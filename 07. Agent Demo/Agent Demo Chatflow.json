{
  "nodes": [
    {
      "id": "conversationalAgent_0",
      "position": {
        "x": 997,
        "y": 136
      },
      "type": "customNode",
      "data": {
        "id": "conversationalAgent_0",
        "label": "Conversational Agent",
        "version": 3,
        "name": "conversationalAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "rows": 4,
            "default": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
            "optional": true,
            "additionalParams": true,
            "id": "conversationalAgent_0-input-systemMessage-string",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "conversationalAgent_0-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Allowed Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "conversationalAgent_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalAgent_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "conversationalAgent_0-input-memory-BaseChatMemory",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalAgent_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "tools": [
            "{{calculator_0.data.instance}}",
            "{{tavilyAPI_0.data.instance}}",
            "{{chainTool_0.data.instance}}"
          ],
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "memory": "{{bufferWindowMemory_0.data.instance}}",
          "systemMessage": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
          "inputModeration": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalAgent_0-output-conversationalAgent-AgentExecutor|BaseChain|Runnable",
            "name": "conversationalAgent",
            "label": "AgentExecutor",
            "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 441,
      "positionAbsolute": {
        "x": 997,
        "y": 136
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 586.6326628256354,
        "y": -599.4213033368454
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number",
            "display": true
          },
          {
            "label": "Safety Settings",
            "name": "safetySettings",
            "type": "array",
            "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-settings\">official guide</a> on how to use Safety Settings",
            "array": [
              {
                "label": "Harm Category",
                "name": "harmCategory",
                "type": "options",
                "options": [
                  {
                    "label": "Dangerous",
                    "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "description": "Promotes, facilitates, or encourages harmful acts."
                  },
                  {
                    "label": "Harassment",
                    "name": "HARM_CATEGORY_HARASSMENT",
                    "description": "Negative or harmful comments targeting identity and/or protected attributes."
                  },
                  {
                    "label": "Hate Speech",
                    "name": "HARM_CATEGORY_HATE_SPEECH",
                    "description": "Content that is rude, disrespectful, or profane."
                  },
                  {
                    "label": "Sexually Explicit",
                    "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "description": "Contains references to sexual acts or other lewd content."
                  },
                  {
                    "label": "Civic Integrity",
                    "name": "HARM_CATEGORY_CIVIC_INTEGRITY",
                    "description": "Election-related queries."
                  }
                ]
              },
              {
                "label": "Harm Block Threshold",
                "name": "harmBlockThreshold",
                "type": "options",
                "options": [
                  {
                    "label": "None",
                    "name": "BLOCK_NONE",
                    "description": "Always show regardless of probability of unsafe content"
                  },
                  {
                    "label": "Only High",
                    "name": "BLOCK_ONLY_HIGH",
                    "description": "Block when high probability of unsafe content"
                  },
                  {
                    "label": "Medium and Above",
                    "name": "BLOCK_MEDIUM_AND_ABOVE",
                    "description": "Block when medium or high probability of unsafe content"
                  },
                  {
                    "label": "Low and Above",
                    "name": "BLOCK_LOW_AND_ABOVE",
                    "description": "Block when low, medium or high probability of unsafe content"
                  },
                  {
                    "label": "Threshold Unspecified (Default Threshold)",
                    "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                    "description": "Threshold is unspecified, block using default threshold"
                  }
                ]
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-safetySettings-array",
            "display": true
          },
          {
            "label": "Thinking Budget",
            "name": "thinkingBudget",
            "type": "number",
            "description": "Guides the number of thinking tokens. -1 for dynamic, 0 to disable, or positive integer (Gemini 2.5 models).",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "show": {
              "modelName": [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-2.5-flash-lite"
              ]
            },
            "id": "chatGoogleGenerativeAI_0-input-thinkingBudget-number",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.5-flash",
          "customModelName": "",
          "temperature": "0.8",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "safetySettings": "",
          "thinkingBudget": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": 586.6326628256354,
        "y": -599.4213033368454
      },
      "dragging": false
    },
    {
      "id": "bufferWindowMemory_0",
      "position": {
        "x": 1004.0079148363645,
        "y": 590.9528787117226
      },
      "type": "customNode",
      "data": {
        "id": "bufferWindowMemory_0",
        "label": "Buffer Window Memory",
        "version": 2,
        "name": "bufferWindowMemory",
        "type": "BufferWindowMemory",
        "baseClasses": [
          "BufferWindowMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
        "inputParams": [
          {
            "label": "Size",
            "name": "k",
            "type": "number",
            "default": "4",
            "description": "Window of size k to surface the last k back-and-forth to use as memory.",
            "id": "bufferWindowMemory_0-input-k-number",
            "display": true
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "optional": true,
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "k": "4",
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
            "name": "bufferWindowMemory",
            "label": "BufferWindowMemory",
            "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
            "type": "BufferWindowMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 337,
      "selected": false,
      "positionAbsolute": {
        "x": 1004.0079148363645,
        "y": 590.9528787117226
      },
      "dragging": false
    },
    {
      "id": "calculator_0",
      "position": {
        "x": 266.8838923999667,
        "y": 64.31614422921191
      },
      "type": "customNode",
      "data": {
        "id": "calculator_0",
        "label": "Calculator",
        "version": 1,
        "name": "calculator",
        "type": "Calculator",
        "baseClasses": [
          "Calculator",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Perform calculations on response",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
            "name": "calculator",
            "label": "Calculator",
            "description": "Perform calculations on response",
            "type": "Calculator | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 149,
      "selected": false,
      "positionAbsolute": {
        "x": 266.8838923999667,
        "y": 64.31614422921191
      },
      "dragging": false
    },
    {
      "id": "tavilyAPI_0",
      "position": {
        "x": 265.89536606238323,
        "y": 232.36562161839453
      },
      "type": "customNode",
      "data": {
        "id": "tavilyAPI_0",
        "label": "Tavily API",
        "version": 1.2,
        "name": "tavilyAPI",
        "type": "TavilyAPI",
        "baseClasses": [
          "TavilyAPI",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Wrapper around TavilyAPI - A specialized search engine designed for LLMs and AI agents",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "tavilyApi"
            ],
            "id": "tavilyAPI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Topic",
            "name": "topic",
            "type": "options",
            "options": [
              {
                "label": "General",
                "name": "general"
              },
              {
                "label": "News",
                "name": "news"
              }
            ],
            "default": "general",
            "description": "The category of the search. News for real-time updates, general for broader searches",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-topic-options",
            "display": true
          },
          {
            "label": "Search Depth",
            "name": "searchDepth",
            "type": "options",
            "options": [
              {
                "label": "Basic",
                "name": "basic"
              },
              {
                "label": "Advanced",
                "name": "advanced"
              }
            ],
            "default": "basic",
            "description": "The depth of the search. Advanced costs 2 API Credits, basic costs 1",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-searchDepth-options",
            "display": true
          },
          {
            "label": "Chunks Per Source",
            "name": "chunksPerSource",
            "type": "number",
            "default": 3,
            "description": "Number of content chunks per source (1-3). Only for advanced search",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-chunksPerSource-number",
            "display": true
          },
          {
            "label": "Max Results",
            "name": "maxResults",
            "type": "number",
            "default": 5,
            "additionalParams": true,
            "description": "Maximum number of search results (0-20)",
            "optional": true,
            "id": "tavilyAPI_0-input-maxResults-number",
            "display": true
          },
          {
            "label": "Time Range",
            "name": "timeRange",
            "type": "options",
            "options": [
              {
                "label": "Day",
                "name": "day"
              },
              {
                "label": "Week",
                "name": "week"
              },
              {
                "label": "Month",
                "name": "month"
              },
              {
                "label": "Year",
                "name": "year"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "description": "Time range to filter results",
            "id": "tavilyAPI_0-input-timeRange-options",
            "display": true
          },
          {
            "label": "Days",
            "name": "days",
            "type": "number",
            "default": 7,
            "additionalParams": true,
            "description": "Number of days back from current date (only for news topic)",
            "optional": true,
            "id": "tavilyAPI_0-input-days-number",
            "display": true
          },
          {
            "label": "Include Answer",
            "name": "includeAnswer",
            "type": "boolean",
            "default": false,
            "description": "Include an LLM-generated answer to the query",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-includeAnswer-boolean",
            "display": true
          },
          {
            "label": "Include Raw Content",
            "name": "includeRawContent",
            "type": "boolean",
            "default": false,
            "description": "Include cleaned and parsed HTML content of each result",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-includeRawContent-boolean",
            "display": true
          },
          {
            "label": "Include Images",
            "name": "includeImages",
            "type": "boolean",
            "default": false,
            "description": "Include image search results",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-includeImages-boolean",
            "display": true
          },
          {
            "label": "Include Image Descriptions",
            "name": "includeImageDescriptions",
            "type": "boolean",
            "default": false,
            "description": "Include descriptive text for each image",
            "additionalParams": true,
            "optional": true,
            "id": "tavilyAPI_0-input-includeImageDescriptions-boolean",
            "display": true
          },
          {
            "label": "Include Domains",
            "name": "includeDomains",
            "type": "string",
            "optional": true,
            "description": "Comma-separated list of domains to include in results",
            "additionalParams": true,
            "id": "tavilyAPI_0-input-includeDomains-string",
            "display": true
          },
          {
            "label": "Exclude Domains",
            "name": "excludeDomains",
            "type": "string",
            "optional": true,
            "description": "Comma-separated list of domains to exclude from results",
            "additionalParams": true,
            "id": "tavilyAPI_0-input-excludeDomains-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "topic": "general",
          "searchDepth": "basic",
          "chunksPerSource": 3,
          "maxResults": 5,
          "timeRange": "",
          "days": 7,
          "includeAnswer": "",
          "includeRawContent": "",
          "includeImages": "",
          "includeImageDescriptions": "",
          "includeDomains": "",
          "excludeDomains": ""
        },
        "outputAnchors": [
          {
            "id": "tavilyAPI_0-output-tavilyAPI-TavilyAPI|Tool|StructuredTool|Runnable",
            "name": "tavilyAPI",
            "label": "TavilyAPI",
            "description": "Wrapper around TavilyAPI - A specialized search engine designed for LLMs and AI agents",
            "type": "TavilyAPI | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 334,
      "selected": false,
      "positionAbsolute": {
        "x": 265.89536606238323,
        "y": 232.36562161839453
      },
      "dragging": false
    },
    {
      "id": "chainTool_0",
      "position": {
        "x": 271.20819935935606,
        "y": 586.1048616676732
      },
      "type": "customNode",
      "data": {
        "id": "chainTool_0",
        "label": "Chain Tool",
        "version": 1,
        "name": "chainTool",
        "type": "ChainTool",
        "baseClasses": [
          "ChainTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a chain as allowed tool for agent",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "name",
            "type": "string",
            "placeholder": "state-of-union-qa",
            "id": "chainTool_0-input-name-string",
            "display": true
          },
          {
            "label": "Chain Description",
            "name": "description",
            "type": "string",
            "rows": 3,
            "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
            "id": "chainTool_0-input-description-string",
            "display": true
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "type": "boolean",
            "optional": true,
            "id": "chainTool_0-input-returnDirect-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Base Chain",
            "name": "baseChain",
            "type": "BaseChain",
            "id": "chainTool_0-input-baseChain-BaseChain",
            "display": true
          }
        ],
        "inputs": {
          "name": "koki",
          "description": "tools ini digunakan untuk membuat resep makanan",
          "returnDirect": "",
          "baseChain": "{{llmChain_0.data.instance}}"
        },
        "outputAnchors": [
          {
            "id": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "chainTool",
            "label": "ChainTool",
            "description": "Use a chain as allowed tool for agent",
            "type": "ChainTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 609,
      "selected": false,
      "positionAbsolute": {
        "x": 271.20819935935606,
        "y": 586.1048616676732
      },
      "dragging": false
    },
    {
      "id": "llmChain_0",
      "position": {
        "x": -104.38153988089152,
        "y": 59.56022384150347
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_0",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_0-input-chainName-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_0-input-model-BaseLanguageModel",
            "display": true
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_0-input-prompt-BasePromptTemplate",
            "display": true
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_0-input-outputParser-BaseLLMOutputParser",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_1.data.instance}}",
          "prompt": "{{promptTemplate_0.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_0-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 514,
      "selected": false,
      "positionAbsolute": {
        "x": -104.38153988089152,
        "y": 59.56022384150347
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_1",
      "position": {
        "x": -722.80593443747,
        "y": 10.979667307787167
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_1",
        "label": "ChatGoogleGenerativeAI",
        "version": 3.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_1-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_1-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topK-number",
            "display": true
          },
          {
            "label": "Safety Settings",
            "name": "safetySettings",
            "type": "array",
            "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-settings\">official guide</a> on how to use Safety Settings",
            "array": [
              {
                "label": "Harm Category",
                "name": "harmCategory",
                "type": "options",
                "options": [
                  {
                    "label": "Dangerous",
                    "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "description": "Promotes, facilitates, or encourages harmful acts."
                  },
                  {
                    "label": "Harassment",
                    "name": "HARM_CATEGORY_HARASSMENT",
                    "description": "Negative or harmful comments targeting identity and/or protected attributes."
                  },
                  {
                    "label": "Hate Speech",
                    "name": "HARM_CATEGORY_HATE_SPEECH",
                    "description": "Content that is rude, disrespectful, or profane."
                  },
                  {
                    "label": "Sexually Explicit",
                    "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "description": "Contains references to sexual acts or other lewd content."
                  },
                  {
                    "label": "Civic Integrity",
                    "name": "HARM_CATEGORY_CIVIC_INTEGRITY",
                    "description": "Election-related queries."
                  }
                ]
              },
              {
                "label": "Harm Block Threshold",
                "name": "harmBlockThreshold",
                "type": "options",
                "options": [
                  {
                    "label": "None",
                    "name": "BLOCK_NONE",
                    "description": "Always show regardless of probability of unsafe content"
                  },
                  {
                    "label": "Only High",
                    "name": "BLOCK_ONLY_HIGH",
                    "description": "Block when high probability of unsafe content"
                  },
                  {
                    "label": "Medium and Above",
                    "name": "BLOCK_MEDIUM_AND_ABOVE",
                    "description": "Block when medium or high probability of unsafe content"
                  },
                  {
                    "label": "Low and Above",
                    "name": "BLOCK_LOW_AND_ABOVE",
                    "description": "Block when low, medium or high probability of unsafe content"
                  },
                  {
                    "label": "Threshold Unspecified (Default Threshold)",
                    "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                    "description": "Threshold is unspecified, block using default threshold"
                  }
                ]
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-safetySettings-array",
            "display": true
          },
          {
            "label": "Thinking Budget",
            "name": "thinkingBudget",
            "type": "number",
            "description": "Guides the number of thinking tokens. -1 for dynamic, 0 to disable, or positive integer (Gemini 2.5 models).",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "show": {
              "modelName": [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-2.5-flash-lite"
              ]
            },
            "id": "chatGoogleGenerativeAI_1-input-thinkingBudget-number",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.5-flash",
          "customModelName": "",
          "temperature": "0.8",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "safetySettings": "",
          "thinkingBudget": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": -722.80593443747,
        "y": 10.979667307787167
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_0",
      "position": {
        "x": -722.8059344374701,
        "y": 695.3903886755699
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_0",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_0-input-template-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_0-input-promptValues-json",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Berdasarkan kalimat, buatkan resep masakan yang enak beserta cara memasaknya\n\nkalimat: {input}",
          "promptValues": "{\"input\":\"{{question}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 519,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -722.8059344374701,
        "y": 695.3903886755699
      }
    }
  ],
  "edges": [
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalAgent_0-conversationalAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferWindowMemory_0",
      "sourceHandle": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferWindowMemory_0-bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory-conversationalAgent_0-conversationalAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "calculator_0",
      "sourceHandle": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-conversationalAgent_0-conversationalAgent_0-input-tools-Tool"
    },
    {
      "source": "tavilyAPI_0",
      "sourceHandle": "tavilyAPI_0-output-tavilyAPI-TavilyAPI|Tool|StructuredTool|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "tavilyAPI_0-tavilyAPI_0-output-tavilyAPI-TavilyAPI|Tool|StructuredTool|Runnable-conversationalAgent_0-conversationalAgent_0-input-tools-Tool"
    },
    {
      "source": "chainTool_0",
      "sourceHandle": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "conversationalAgent_0",
      "targetHandle": "conversationalAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "chainTool_0-chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable-conversationalAgent_0-conversationalAgent_0-input-tools-Tool"
    },
    {
      "source": "llmChain_0",
      "sourceHandle": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
      "target": "chainTool_0",
      "targetHandle": "chainTool_0-input-baseChain-BaseChain",
      "type": "buttonedge",
      "id": "llmChain_0-llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable-chainTool_0-chainTool_0-input-baseChain-BaseChain"
    },
    {
      "source": "chatGoogleGenerativeAI_1",
      "sourceHandle": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_1-chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "promptTemplate_0",
      "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
    }
  ]
}